{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93559a2d-1951-45f1-97cc-234b93cff83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Loading cached SentenceBERT embeddings...\n",
      "\n",
      "[*] Training ensemble model...\n",
      "\n",
      "============================================================\n",
      "ENSEMBLE MODEL PERFORMANCE\n",
      "============================================================\n",
      "Accuracy: 80.85%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Abusive       0.83      0.79      0.81      2673\n",
      "     Abusive       0.79      0.83      0.81      2517\n",
      "\n",
      "    accuracy                           0.81      5190\n",
      "   macro avg       0.81      0.81      0.81      5190\n",
      "weighted avg       0.81      0.81      0.81      5190\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2119  554]\n",
      " [ 440 2077]]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tamil Abusive Text Detection\n",
    "Model: TF-IDF (Char) + SentenceBERT + RF + ExtraTrees\n",
    "Optimized for CPU\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "def clean_tamil_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+|#\", \"\", text)\n",
    "    text = re.sub(r\"[^\\u0B80-\\u0BFFa-zA-Z0-9\\s]\", \"\", text)\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "DATASET_PATH = r\"C:\\Users\\roahi\\OneDrive\\Desktop\\train2.csv\"\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH, usecols=[\"Text\", \"Class\"]).dropna()\n",
    "df[\"clean_text\"] = df[\"Text\"].apply(clean_tamil_text)\n",
    "\n",
    "texts = df[\"clean_text\"].tolist()\n",
    "labels = df[\"Class\"].astype(np.int8).values\n",
    "\n",
    "\n",
    "X_train_texts, X_test_texts, y_train, y_test = train_test_split(\n",
    "    texts,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    stratify=labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    ngram_range=(3, 5),\n",
    "    min_df=5,\n",
    "    max_features=50000\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_texts)\n",
    "X_test_tfidf = tfidf.transform(X_test_texts)\n",
    "EMB_DIR = \"cached_embeddings\"\n",
    "os.makedirs(EMB_DIR, exist_ok=True)\n",
    "\n",
    "train_emb_path = os.path.join(EMB_DIR, \"X_train_sbert.npy\")\n",
    "test_emb_path = os.path.join(EMB_DIR, \"X_test_sbert.npy\")\n",
    "\n",
    "if os.path.exists(train_emb_path) and os.path.exists(test_emb_path):\n",
    "    print(\"[*] Loading cached SentenceBERT embeddings...\")\n",
    "    X_train_emb = np.load(train_emb_path)\n",
    "    X_test_emb = np.load(test_emb_path)\n",
    "else:\n",
    "    print(\"[*] Encoding text using SentenceBERT...\")\n",
    "    encoder = SentenceTransformer(\n",
    "        \"paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        device=\"cpu\"\n",
    "    )\n",
    "\n",
    "    X_train_emb = encoder.encode(\n",
    "        X_train_texts,\n",
    "        batch_size=128,\n",
    "        convert_to_numpy=True,\n",
    "        show_progress_bar=True\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    X_test_emb = encoder.encode(\n",
    "        X_test_texts,\n",
    "        batch_size=128,\n",
    "        convert_to_numpy=True,\n",
    "        show_progress_bar=True\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    np.save(train_emb_path, X_train_emb)\n",
    "    np.save(test_emb_path, X_test_emb)\n",
    "X_train = hstack([X_train_tfidf, X_train_emb])\n",
    "X_test = hstack([X_test_tfidf, X_test_emb])\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=\"sqrt\",\n",
    "    class_weight={0: 1, 1: 1.5},\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "et = ExtraTreesClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=\"sqrt\",\n",
    "    class_weight={0: 1, 1: 1.5},\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[(\"rf\", rf), (\"et\", et)],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(\"\\n[*] Training ensemble model...\")\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ENSEMBLE MODEL PERFORMANCE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\\n\")\n",
    "\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=[\"Non-Abusive\", \"Abusive\"]\n",
    "))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
